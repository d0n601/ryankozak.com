I"=+<p>This article isn‚Äôt meant to discuss what web scraping is, or why it‚Äôs valuable to do. What I intend to focus on instead, is how modern web application architecture is changing how web scraping can/must be performed. A nice <a href="https://datawhatnow.com/introduction-web-scraping-python/?utm_source=hackernewsletter&amp;utm_medium=email&amp;utm_term=fav&amp;utm_source=Hacker+Newsletter&amp;utm_campaign=b91881aad0-EMAIL_CAMPAIGN_2017_10_27&amp;utm_medium=email&amp;utm_term=0_e505c88a2e-b91881aad0-399347153">article discussing traditional web scraping</a> just appeared in <a href="http://www.hackernewsletter.com/">Hacker Newsletter</a> #375 by <a title="View profile" href="https://github.com/Weenkus" target="_blank" rel="noopener" data-slimstat="5"><span class="github-names">Vinko Kod≈æoman</span></a>. His article tipped my motivation to write this.</p>

<h3 id="traditional-scraping">Traditional Scraping</h3>

<p>Up until recently, data was typically harvested by parsing a site‚Äôs markup. Browser automation frameworks allowed this to be achieved in various ways, and I‚Äôve used both <a href="https://pypi.python.org/pypi/beautifulsoup4/">Beautiful Soup</a> and <a href="http://docs.seleniumhq.org/">Selenium</a> to achieve what I needed to in the past. Vinko discusses in his article another library <a href="http://lxml.de/">lxml,</a> which I‚Äôve not tried. His explanation of lxml and how it interacts with the DOM is good enough to allow general understanding of the way scraping is performed. Essentially, your bot reads the markup, and categorizes relevant data for you.</p>

<h3 id="entering-front-end--rest-apis">Entering Front-End &amp; REST APIs</h3>

<h4 id="background">Background</h4>

<p>Modern web applications often implement some sort of front-end framework, such as <a href="https://angularjs.org/">Angular</a>, <a href="https://reactjs.org/">React</a>, <a href="https://vuejs.org/">Vue</a>, etc. These JavaScript frameworks communicate to a web API of some sort to retrieve data. This means that multiple requests are required before the actual markup is built that contains useful data. Typically those requests require some sort of parameters to return only a subset of the data to you in the markup.</p>

<h4 id="problem">Problem</h4>

<p>Earlier this year I was tasked with developing a scraper to collect data from a website which used Angular 2 on its front end. The requirement was that it collect business listings from each region on the site, however, the listings were only shown based on the boundaries of a Google Map frame users were able to drag around. There was no way to iterate the markup via pagination, and no directory/list of all existing regions. Traditional scraping of the markup wouldn‚Äôt work, because the content was rendered dynamically. I couldn‚Äôt¬† figure out how to use BS4 for this task, and I was stumped.</p>

<h4 id="solution">Solution</h4>

<p>I began to browse the site in question and examine the requests that it made via <a href="https://chrome.google.com/webstore/detail/postman/fhbjgbiflinjbdggehcddcbncdddomop?hl=en">Postman.</a> What I discovered was that life was much easier under this new type of web app architecture. AJAX calls were made via GET requests to return the data I was looking to collect. After spending a little time browsing the site to map the required endpoints of the REST API and their parameters, harvesting the data was substantially easier via their own API than it ever was¬† in the days of parsing markup. Data was returned in JSON format, and could be added directly into a Mongo collection. Essentially, all the data could be copied from the website in a matter of half a minute or so.</p>

<h4 id="cool-story-bro-but-example">Cool Story Bro, But Example?</h4>

<p>What inspired me to write this article was a project at work. Since paperwork and money are involved, I can‚Äôt provide the examples I wish I could. However, here‚Äôs an example using a site in the <span style="color: #339966;">Marijuana</span> industry üòâ</p>

<p><strong>Example Scenario:</strong> You‚Äôre wanting to know every single place to buy <span style="color: #339966;">marijuana</span> in the country. Because you love <span style="color: #339966;">marijuana</span>!</p>

<p>First, browse Leafly.com (a place to find you some <span style="color: #339966;">marijuana</span>) and check out what‚Äôs going on in the background.<a href="/wp-content/uploads/2017/10/Screenshot-from-2017-10-27-10-45-32.png"><img class="wp-image-507 size-large alignnone" src="/wp-content/uploads/2017/10/Screenshot-from-2017-10-27-10-45-32-1024x557.png" alt="" width="660" height="359" srcset="/wp-content/uploads/2017/10/Screenshot-from-2017-10-27-10-45-32-1024x557.png 1024w, /wp-content/uploads/2017/10/Screenshot-from-2017-10-27-10-45-32-300x163.png 300w, /wp-content/uploads/2017/10/Screenshot-from-2017-10-27-10-45-32-768x418.png 768w" sizes="(max-width: 660px) 100vw, 660px" /></a></p>

<p>¬†</p>

<p>You can see a post request is made each time you change the map, and the request includes the top left and bottom right corners of the map frame.<a href="/wp-content/uploads/2017/10/Screenshot-from-2017-10-27-10-45-15.png"><img class="aligncenter wp-image-508 size-large" src="/wp-content/uploads/2017/10/Screenshot-from-2017-10-27-10-45-15-1024x351.png" alt="" width="660" height="226" srcset="/wp-content/uploads/2017/10/Screenshot-from-2017-10-27-10-45-15-1024x351.png 1024w, /wp-content/uploads/2017/10/Screenshot-from-2017-10-27-10-45-15-300x103.png 300w, /wp-content/uploads/2017/10/Screenshot-from-2017-10-27-10-45-15-768x263.png 768w" sizes="(max-width: 660px) 100vw, 660px" /></a></p>

<p>Here is a Python script to make a POST request to the API endpoints on Leafly with the parameters that we just discovered. We‚Äôve ignored sending any headers at all, and set the ‚ÄúTake‚Äù parameter to be absurd.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="c1">#from pymongo import MongoClient
</span>

<span class="k">class</span> <span class="nc">LeaflyHarvest</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="s">"""
    Leafly.com proof of concept data harvester.
    """</span>

    <span class="k">def</span> <span class="nf">scrape_dispensaries</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""
        Scrape all dispensaries from Leafly.com.
        :return: void
        """</span>

        <span class="c1"># API Endpoint to search for stuff on Leafly
</span>        <span class="n">url</span> <span class="o">=</span> <span class="s">"https://www.leafly.com/finder/searchnext"</span>

        <span class="c1"># Body of the request
</span>        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"NorthwestLatitude"</span><span class="p">:</span> <span class="mf">57.70487627437739</span><span class="p">,</span>
            <span class="s">"NorthwestLongitude"</span><span class="p">:</span> <span class="o">-</span><span class="mf">138.49595341516113</span><span class="p">,</span>
            <span class="s">"Page"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s">"PremiumLocation"</span><span class="p">:</span> <span class="mi">84720</span><span class="p">,</span>
            <span class="s">"PremiumLocationType"</span><span class="p">:</span> <span class="s">"ZipCode"</span><span class="p">,</span>
            <span class="s">"SoutheastLatitude"</span><span class="p">:</span> <span class="mf">12.898819268131966</span><span class="p">,</span>
            <span class="s">"SoutheastLongitude"</span><span class="p">:</span> <span class="o">-</span><span class="mf">33.027203415161125</span><span class="p">,</span>
            <span class="s">"Take"</span><span class="p">:</span> <span class="mi">9000</span>
        <span class="p">}</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># Endpoint's response to you
</span>        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s">"Content-Type"</span><span class="p">:</span> <span class="s">"application/json"</span><span class="p">}).</span><span class="n">json</span><span class="p">()</span>

        <span class="c1"># Within this loop you could filter/store data...
</span>        <span class="k">for</span> <span class="n">dispensary</span> <span class="ow">in</span> <span class="n">response</span><span class="p">[</span><span class="s">"Results"</span><span class="p">]:</span>
            <span class="k">print</span><span class="p">(</span><span class="n">dispensary</span><span class="p">[</span><span class="s">'Name'</span><span class="p">])</span>

        <span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="p">[</span><span class="s">"Results"</span><span class="p">]))</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">LeaflyHarvest</span><span class="p">().</span><span class="n">scrape_dispensaries</span><span class="p">()</span>
</code></pre></div></div>

<p>The output will be something like‚Ä¶</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.......
.......
Fullerton Flowers
New Generation
Sierra Vista Phytoceuticals
Hamilton Wellness Center
4038
</code></pre></div></div>

<p>If this wasn‚Äôt a proof of concept, you could do much better than this by adjusting the coordinates a few times and taking multiple samples. There are a lot things to change if you were trying to make a legitimate Leafly scraper, I know. I‚Äôm just demonstrating that the ability to grab over 4k listings in a few seconds is pretty neat.</p>

<h4 id="conclusion">Conclusion</h4>

<p>It‚Äôs getting easier to scrape large amounts of data when front-end frameworks talk to API‚Äôs with no authentication, especially if they have no limit to the request size.</p>

<p>P.S. If you‚Äôre ethical you will obey the terms of service posted on any site. You‚Äôll then determine that running the provided proof of concept is wrong (don‚Äôt do it).</p>
:ET